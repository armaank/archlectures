{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text2Representation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azoR8ww72KbO"
      },
      "source": [
        "# Text2Representation\n",
        "\n",
        "Synthesizing architecture imagery with CLIP-guided generative latent space search. Based on the implementation [here](https://github.com/galatolofederico/clip-glass), with a StyleGan2 trained on an architecture corpus. \n",
        "\n",
        "## Instructions\n",
        "\n",
        "1) Click the play button of the blocks titled \"Initialization\" and wait for it to finish the setup\n",
        "\n",
        "2) Select a model and a enter a phrase in the form titled \"Text2Representation\"\n",
        "\n",
        "3) Click the play button of the block titled \"Text2Representation\" to generate \n",
        "imagery from the phrase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFYmVxNS3ECT",
        "cellView": "form"
      },
      "source": [
        "%%capture\n",
        "#@title Initialization - Setup\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "nvcc = subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"utf-8\")\n",
        "version = re.findall(\"release (\\d+\\.\\d+)\", nvcc)[0]\n",
        "\n",
        "pytorch_suffix = {\n",
        "    \"10.0\": \"+cu100\",\n",
        "    \"10.1\": \"+cu101\",\n",
        "    \"10.2\": \"\",\n",
        "}\n",
        "\n",
        "pytorch_version = \"1.7.1\" + (pytorch_suffix[version] if version in pytorch_suffix else \"+cu110\")\n",
        "torchvision_version = \"0.8.2\" + (pytorch_suffix[version] if version in pytorch_suffix else \"+cu110\")\n",
        "%rm -rf archlectures\n",
        "!git clone https://github.com/armaank/archlectures.git\n",
        "%cd archlectures/generative\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOYiy6MUATAW",
        "cellView": "form"
      },
      "source": [
        "#@title Initialization - Download Models\n",
        "%%capture\n",
        "%%sh\n",
        "chmod 755 get_models.sh\n",
        "./get_models.sh\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugNAQ6tdAYQ5",
        "cellView": "form"
      },
      "source": [
        "#@title Initialization - Install Requirements\n",
        "%%capture\n",
        "\n",
        "# %cd archlectures/generative/stylclip/\n",
        "%pwd\n",
        "\n",
        "try:\n",
        "  import torch\n",
        "except:\n",
        "  !pip install torch=={pytorch_version} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "try:\n",
        "  import torchvision\n",
        "except:\n",
        "  !pip install torchvision=={torchvision_version} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!pip install pytorch_pretrained_biggan pymoo kornia ftfy tensorboard"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfXK5iLY3rjQ",
        "cellView": "form"
      },
      "source": [
        "#@title Text2Representation\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.algorithms.so_genetic_algorithm import GA\n",
        "from pymoo.factory import get_algorithm, get_decision_making, get_decomposition\n",
        "from pymoo.visualization.scatter import Scatter\n",
        "import torchvision\n",
        "from IPython.display import Image, display\n",
        "import urllib.request\n",
        "\n",
        "print(os.getcwd())\n",
        "%cd stylclip/\n",
        "from config import get_config\n",
        "from problem import GenerationProblem\n",
        "from operators import get_operators\n",
        "\n",
        "phrase = \"big school for botanical sciences \" #@param {type:\"string\"}\n",
        "model = \"Adaily_A\" #@param [\"Adaily_A\", \"Adaily_B\"]\n",
        "save_each =  10#@param {type:\"number\"}\n",
        "generations = 100 #@param {type:\"number\"}\n",
        "\n",
        "target = phrase\n",
        "config = model\n",
        "# if config == \"GPT2\":\n",
        "#   try:\n",
        "#     urllib.request.urlretrieve(target, \"./target\")\n",
        "#     target = \"./target\"\n",
        "#   except Exception as e:\n",
        "#     print(e)\n",
        "#     raise Exception(\"Target must be a vaild URL when using GPT2\")\n",
        "    \n",
        "# if config==\"Adaily\":\n",
        "#   ! ./download-weights.sh Adaily\n",
        "\n",
        "# if \"ffhq\" in config:\n",
        "#   ! ./download-weights.sh StyleGAN2-ffhq\n",
        "# if \"church\" in config:\n",
        "#   ! ./download-weights.sh StyleGAN2-church\n",
        "# if \"car\" in config:\n",
        "#   ! ./download-weights.sh StyleGAN2-car\n",
        "# if config == \"GPT2\":\n",
        "#   ! ./download-weights.sh GPT2\n",
        "\n",
        "config = argparse.Namespace(\n",
        "    config=config,\n",
        "    target=target,\n",
        "    device=\"cuda\",\n",
        "    generations=generations,\n",
        "    save_each=save_each,\n",
        "    tmp_folder=\"./tmp\"\n",
        ")\n",
        "\n",
        "vars(config).update(get_config(config.config))\n",
        "\n",
        "\n",
        "iteration = 0\n",
        "def save_callback(algorithm):\n",
        "    global iteration\n",
        "    global config\n",
        "\n",
        "    iteration += 1\n",
        "    if iteration % config.save_each == 0 or iteration == config.generations:\n",
        "        if config.problem_args[\"n_obj\"] == 1:\n",
        "            sortedpop = sorted(algorithm.pop, key=lambda p: p.F)\n",
        "            X = np.stack([p.X for p in sortedpop])  \n",
        "        else:\n",
        "            X = algorithm.pop.get(\"X\")\n",
        "        \n",
        "        ls = config.latent(config)\n",
        "        ls.set_from_population(X)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            generated = algorithm.problem.generator.generate(ls, minibatch=config.batch_size)\n",
        "            name = \"genetic-it-%d.jpg\" % (iteration) if iteration < config.generations else \"genetic-it-final.jpg\"\n",
        "\n",
        "            if config.task == \"txt2img\":\n",
        "                algorithm.problem.generator.save(generated, os.path.join(config.tmp_folder, name))\n",
        "                display(Image(os.path.join(config.tmp_folder, name)))\n",
        "            elif config.task == \"img2txt\":\n",
        "                print(\"\\n\".join(generated))\n",
        "        \n",
        "\n",
        "problem = GenerationProblem(config)\n",
        "operators = get_operators(config)\n",
        "\n",
        "if not os.path.exists(config.tmp_folder): os.mkdir(config.tmp_folder)\n",
        "\n",
        "algorithm = get_algorithm(\n",
        "    config.algorithm,\n",
        "    pop_size=config.pop_size,\n",
        "    sampling=operators[\"sampling\"],\n",
        "    crossover=operators[\"crossover\"],\n",
        "    mutation=operators[\"mutation\"],\n",
        "    eliminate_duplicates=True,\n",
        "    callback=save_callback,\n",
        "    **(config.algorithm_args[config.algorithm] if \"algorithm_args\" in config and config.algorithm in config.algorithm_args else dict())\n",
        ")\n",
        "\n",
        "res = minimize(\n",
        "    problem,\n",
        "    algorithm,\n",
        "    (\"n_gen\", config.generations),\n",
        "    save_history=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "pickle.dump(dict(\n",
        "    X = res.X,\n",
        "    F = res.F,\n",
        "    G = res.G,\n",
        "    CV = res.CV,\n",
        "), open(os.path.join(config.tmp_folder, \"genetic_result\"), \"wb\"))\n",
        "\n",
        "\n",
        "if config.problem_args[\"n_obj\"] == 1:\n",
        "    X = np.atleast_2d(res.X)\n",
        "else:\n",
        "    try:\n",
        "        result = get_decision_making(\"pseudo-weights\", [0, 1]).do(res.F)\n",
        "    except:\n",
        "        print(\"Warning: cant use pseudo-weights\")\n",
        "        result = get_decomposition(\"asf\").do(res.F, [0, 1]).argmin()\n",
        "    X = res.X[result]\n",
        "    X = np.atleast_2d(X)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"RESULT\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "ls = config.latent(config)\n",
        "ls.set_from_population(X)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = problem.generator.generate(ls)\n",
        "\n",
        "if config.task == \"txt2img\":\n",
        "    problem.generator.save(generated, os.path.join(config.tmp_folder, \"output.jpg\"))\n",
        "    display(Image(os.path.join(config.tmp_folder, \"output.jpg\")))\n",
        "elif config.task == \"img2txt\":\n",
        "    print(generated)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
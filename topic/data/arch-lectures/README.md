## arch-lectures dataset 

### Description and Use

Download the data by running `python3 get_dataset.py`

`raw_data` is the original data as scrapped from YouTube. 

`preprocessed` contains pre-processed text that was the direct input to the model. 


### Motivation

This dataset was created to analyze textual data from architecture lectures on YouTube.
The hypothesis was that there would be semantic differences in how architecture is
discussed at different schools, among others. This dataset was created by Jesse Basset
and analyzed by Jesse, Armaan Kohli and Anna Konvicka. This dataset and associated works 
were funded by the C.V. Starr research foundation at The Cooper Union. 

### Composition

This dataset is composed of autogenerated YouTube captions of architecture lecutres. The
lectures come from 6 different institutions (MIT, Know, GSD, AA, RISD, Cooper Union).
There are a total of 283 documents in the corpus and a total of 2996921 total words
after pre-processing. This dataset is a strict subset of all architecture lectures at
these schools, and consists of only those that were recorded and captioned automatically
by YouTube. There are no labels assigned to this dataset, only the school of origin. 

### Collection Process



### Preprocessing

The preprocessing code is `datahandler.py`. The text files are re-encoded as utf-8 to
remove non-conforming characters. Time stamps are removed, as well as braces and any
other obvious characters that came as artifacts from YouTube captioning system. 

### Uses
Only the current work uses this dataset. This dataset is distributed freely at blahhh

### Maintenance
Contact Armaan Kohli if there are issues

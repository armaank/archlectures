{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os \n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "# will need additional imports for sklearn/umap/etc\n",
    "\n",
    "from datahandler import DataHandler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is an example of how to load a corpus and extract some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Word Count: 2953592\n",
      "Number of Docs in the Corpus: 283\n",
      "[{'inst': 'MIT', 'n_docs': 18, 'wc': 134602}, {'inst': 'Know', 'n_docs': 32, 'wc': 293524}, {'inst': 'GSD', 'n_docs': 37, 'wc': 367047}, {'inst': 'AA', 'n_docs': 137, 'wc': 1532531}, {'inst': 'RISD', 'n_docs': 17, 'wc': 176116}, {'inst': 'CU', 'n_docs': 42, 'wc': 449772}]\n"
     ]
    }
   ],
   "source": [
    "# set random seed\n",
    "# seed = np.random.randint(0, 2**32)\n",
    "seed=123\n",
    "\n",
    "# supply data directory\n",
    "data_dir = os.path.join(os.pardir, \"data\", \"preproc\")\n",
    "# load corpus\n",
    "corpus = DataHandler(data_dir, seed)\n",
    "\n",
    "# print some various information from the corpus\n",
    "print(\"Total Word Count: {}\".format(corpus.total_words))\n",
    "print(\"Number of Docs in the Corpus: {}\".format(corpus.total_docs))\n",
    "\n",
    "# summarize statistics from all institutions in the corpus\n",
    "print(corpus.stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you would train a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'Know', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'GSD', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'AA', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'RISD', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU', 'CU'])\n"
     ]
    }
   ],
   "source": [
    "def model(data):\n",
    "    \"\"\"\n",
    "    model code goes here, probably calls sklearn.something \n",
    "    or umap.something \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dict\n",
    "        data used for model training/validation. data.keys() contains\n",
    "        paths to each text file in the corpus. data.values() stores\n",
    "        the 'label,' which is the intitution the text comes from. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "# pass the data to the model \n",
    "\n",
    "model(corpus.data)\n",
    "# print(corpus.data)\n",
    "print(corpus.data.keys())\n",
    "print(corpus.data.values())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
